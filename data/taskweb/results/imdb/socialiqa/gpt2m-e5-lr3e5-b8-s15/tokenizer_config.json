{
  "add_prefix_space": false,
  "bos_token": "<startoftext>",
  "eos_token": "<endoftext>",
  "name_or_path": "../../outputs/socialiqa/gpt2m-e5-lr3e5-b8-s15",
  "pad_token": "<pad>",
  "special_tokens_map_file": null,
  "tokenizer_class": "GPT2Tokenizer",
  "unk_token": "<|endoftext|>"
}

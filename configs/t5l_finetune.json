{
    "anli_r3": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    },
    "boolq": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 8
    },
    "cb": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 16
    },
    "copa": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 8
    },
    "cosmosqa": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 16
    },
    "hellaswag": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 8
    },
    "imdb": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 16
    },
    "mrpc": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    },
    "piqa": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 8
    },
    "qnli": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 16
    },
    "qqp": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 16
    },
    "quartz": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    },
    "rotten_tomatoes": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    },
    "rte": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 16
    },
    "scitail": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    },
    "snli": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 16
    },
    "socialiqa": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 16
    },
    "stsb": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    },
    "wic": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    },
    "winogrande": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    },
    "wsc": {
        "epochs": 5,
        "learning_rate": 1e-4,
        "batch_size": 32
    }
}